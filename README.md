 **Name** : KAVERI KEERTHI

**Company**: CODTECH IT SOLUTIONS

**ID** : CT04WT27

**Domain** : Data Science

**Duration** : ( 4 Weeks ) March 30th,,2025 to April 30th , 2025.

**Mentor** : NEELA SANTHOSH

# Overview of the Project
## project  :  Data Pipeline Development 
## Objective
The main objective of this project is to develop an automated data pipeline that performs essential steps of data processing‚Äîpreprocessing, transformation, and loading‚Äîto prepare raw data for machine learning tasks or data analysis. This pipeline ensures data is clean, structured, and ready for further use.
* ###  Data Loading:

Importing the dataset using Pandas.

Inspecting the data using .head(), .info(), and .describe().

* ###  Data Preprocessing:

Handling missing values (fillna, dropna).

Removing duplicates and correcting data types.

Cleaning and renaming columns where necessary.

* ###  Data Transformation:

Encoding categorical variables (e.g., using get_dummies() or LabelEncoder).

Feature scaling using StandardScaler or MinMaxScaler.

Feature engineering if applicable.

* ###  Data Splitting:

Separating features and target variable.

Splitting the dataset into training and testing sets using train_test_split.

* ###  Data Saving:

Exporting the processed dataset for reuse using .to_csv().

## üíª Technologies Used
Programming Language: Python

* #### Libraries:

pandas ‚Äì for data manipulation and analysis

scikit-learn ‚Äì for preprocessing and transformation


## üåê Platform
* ####  Development Environment: 
Jupyter Notebook (.ipynb)


## Conclusion
This project successfully demonstrates the creation of a robust data pipeline using Python. By automating the preprocessing and transformation steps, it reduces manual effort and improves data quality for downstream machine learning or analytics tasks. The pipeline can be easily reused or extended for different datasets and business problems.

### Final ETL Processed Data
![task1](https://github.com/user-attachments/assets/e964a3f7-2193-40e4-9397-cd98a69f39a6)












